{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course Project – IME692, Fall 2021\n",
    "\n",
    "## Question\n",
    "\n",
    "#### Develop  a  predictive  model  in  which  the  dependent variable  isCvdVax_DisparityY.  Your  task  is  to examine  the  role  of  different  socioeconomic and  demographic  variables  indetermining  thecovid-19 vaccination rate disparities. Note following points to complete this project.\n",
    "\n",
    "(1)You  are  free  to  choose  any prediction/regression model  to  examine  the  role  of  predictors  in determining CvdVax_DisparityY.  But  use  only  data labelledas “train” for the model building purpose. Evaluate the performance ofyourmodels on the test data.\n",
    "\n",
    "(2)Report three models that give best result on the test dataset. Mentionthe final model that you would select. Explainthe reason for its selection. \n",
    "\n",
    "(3)How would you assess the importance of different predictors in your model? Which predictors are most important in determining the racial disparity in covid-19 vaccinate rate? \n",
    "\n",
    "(4)Areyour  findings  similar  to  the resultsreported  by  authors  in  Table  1of  the  article  (see  the hyperlink above)? If not, why? \n",
    "\n",
    "(5)Upload Python/R code with your project report. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# programme structure and points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# libraries required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# plot modules\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# analysis modules\n",
    "## pre-process and metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "## linear analysis\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet,ElasticNetCV\n",
    "from sklearn.linear_model import Ridge,RidgeCV\n",
    "from sklearn.linear_model import Lasso,LassoCV\n",
    "import statsmodels.api as sm\n",
    "\n",
    "## random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "## svm analysis\n",
    "from sklearn.svm import SVR\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre-process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split test-train\n",
    "\n",
    "- separate independant and dependant variables\n",
    "- dropped state and county columns \n",
    "    - since all variables are numeric except State and County Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "No of testing observations:  225\n",
      "No of training observations:  531\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('ime692_project.csv')\n",
    "\n",
    "# avoid State and County name\n",
    "cols=data.columns[2:].to_list()\n",
    "data=data[cols]\n",
    "\n",
    "# seperate data into test and train based on `Test` indicator\n",
    "pd.options.mode.chained_assignment = None  # default='warn' --> to supress chain assignment warning <--\n",
    "test_data=data.loc[data.Test==1] ## previous indices could be useful ##\n",
    "train_data=data.loc[data.Test==0]\n",
    "\n",
    "# assert split\n",
    "print(\"==========================================\")\n",
    "print(\"No of testing observations: \",test_data.shape[0])\n",
    "print(\"No of training observations: \",train_data.shape[0])\n",
    "print(\"==========================================\")\n",
    "\n",
    "# drop the indicator inplace\n",
    "test_data.drop('Test',axis=1,inplace=True)\n",
    "train_data.drop('Test',axis=1,inplace=True)\n",
    "\n",
    "# sepearate predicted and regressor variables\n",
    "y_test_data=test_data['CvdVax_DisparityY'].tolist()\n",
    "X_test_data=test_data.drop('CvdVax_DisparityY',axis=1)\n",
    "y_train_data=train_data['CvdVax_DisparityY'].tolist()\n",
    "X_train_data=train_data.drop('CvdVax_DisparityY',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalization\n",
    "\n",
    "- z-score normalization is being done on features\n",
    "    - can work with min-max also\n",
    "- no need to normalize dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerInst=StandardScaler()\n",
    "X_train_data_normalized=scalerInst.fit_transform(X_train_data)\n",
    "X_test_data_normalized=scalerInst.fit_transform(X_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which variables to use(PCA)\n",
    "\n",
    "- to check which features to use for further analysis\n",
    "- if small no of features can explain significant variance then work with them only to avoid model becoming complex\n",
    "    - if not then can not avoid features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n=X_train_data_normalized.shape[1]\n",
    "pca=PCA(n_components=n)\n",
    "X_train_data_transformed=pca.fit_transform(X_train_data_normalized)\n",
    "X_test_data_transformed=pca.fit_transform(X_test_data_normalized)\n",
    "\n",
    "foo_ratio=pca.explained_variance_ratio_\n",
    "\n",
    "# to get cummulative\n",
    "var_ratio=[]\n",
    "for i in range(n):\n",
    "    var_ratio.append(100*sum(foo_ratio[0:i+1]))\n",
    "\n",
    "# plotting the variance explined curve (in %)\n",
    "ax=sns.scatterplot(x=np.arange(n)+1,y=var_ratio)\n",
    "ax.axhline(95,color='red')\n",
    "plt.title('variance explained by features')\n",
    "plt.xlabel('# of features')\n",
    "plt.ylabel('vaiance explained in %')\n",
    "plt.xticks(np.arange(n)+1)\n",
    "plt.show() # to avoid text outputs\n",
    "# plt.savefig('pca.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**observations**\n",
    "\n",
    "- PCA is not a good techniqe for this problem \n",
    "    - as no small number set of features explain variance quite significantly\n",
    "    - if around 5-6 features would have explained around 90-95% variance then PCA would have been helpful, but that is not the case here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions for analysis\n",
    "\n",
    "- function `model` uses test and train data with global scope\n",
    "- these functions have been used throught the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function to plot coef plots for models\n",
    "\n",
    "**`function parameters:`**\n",
    "- coefDf: coef data frame with column names from project data\n",
    "- name: [used as an identifier] name to be printed in plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coefplot(coefDf,name):\n",
    "    # to tweak default barh visual\n",
    "    kwargs={\n",
    "    'alpha':0.8,\n",
    "    'edgecolor':'#333',\n",
    "    'facecolor':'#eef',\n",
    "    'width':0.2\n",
    "    }\n",
    "    # to plot barh\n",
    "    (coefDf['Weight of Coeff'].sort_values(ascending = False,kind='mergesort')).plot.barh(figsize=(8,8),**kwargs)\n",
    "    plt.title(f'Importance of Coeff- {name}')\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel('Features')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### general function for models\n",
    "\n",
    "**`function parameters:`**\n",
    "- plot: `Bool`\n",
    "    - by default is set to `False`, to plot feature coeffs set it to `True`float\n",
    "- c: `float`\n",
    "    - tuning hyperparameter used for SVR model, default to 0.1\n",
    "- kernel: ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "    - kernel used for SVR model, default to `linear`\n",
    "- model_title: [used as an identifier]name to be printed in plots etc\n",
    "- modelName: model `class` name imported from `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(modelName,model_title,kernel='linear',c=0.1,plot=False,print=False):\n",
    "    if modelName==SVR:\n",
    "        rm=modelName(kernel=kernel,C=c)\n",
    "    else:\n",
    "        rm=modelName()\n",
    "    \n",
    "    rm.fit(X_train_data_normalized,y_train_data)\n",
    "\n",
    "    # test mse\n",
    "    preds_test=rm.predict(X_test_data_normalized)\n",
    "    MSE_test=mean_squared_error(y_test_data,preds_test)\n",
    "\n",
    "    # train mse\n",
    "    preds_train=rm.predict(X_train_data_normalized)\n",
    "    MSE_train=mean_squared_error(y_train_data,preds_train)\n",
    "\n",
    "    if print==True:\n",
    "        print(model_title)\n",
    "        print(''.center(30,'='))\n",
    "        print('Train MSE =',round(MSE_train,2))\n",
    "        print('Test MSE =',round(MSE_test,2))\n",
    "        print(''.center(30,'='))\n",
    "\n",
    "    if plot==True:\n",
    "        print('Relative Feature Importance Plot')\n",
    "        kwargs={\n",
    "            'alpha':0.8,\n",
    "            'edgecolor':'#333',\n",
    "            'facecolor':'#eef',\n",
    "            'width':0.2\n",
    "            }\n",
    "        # to plot barh\n",
    "        if modelName==RandomForestRegressor:\n",
    "            coefDf = pd.DataFrame(rm.feature_importances_.T, columns=['Weight of Coeff'], index=X_train_data.columns)\n",
    "        else:\n",
    "            coefDf = pd.DataFrame(rm.coef_.T, columns=['Weight of Coeff'], index=X_train_data.columns)\n",
    "        (coefDf['Weight of Coeff'].sort_values(ascending = False,kind='mergesort')).plot.barh(figsize=(8,8),**kwargs)\n",
    "        plt.title(f'Importance of Coeff- {model_title}')\n",
    "        plt.xlabel(\"Importance\")\n",
    "        plt.ylabel('Features')\n",
    "        plt.show()\n",
    "\n",
    "    return {'Model Name':model_title ,'Train':MSE_train,'Test':MSE_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize lists to compare models\n",
    "model_compare=[]\n",
    "linear_models_compare=[]\n",
    "# general plotting and printting settings can be changed here\n",
    "# or one can override these settings in particular function calls\n",
    "want_to_plot=True\n",
    "want_to_print=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normal multiple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm=model(LinearRegression,'Normal Linear Regression',plot=want_to_plot,print=want_to_print)\n",
    "model_compare.append(lm)\n",
    "linear_models_compare.append(lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### restricted regression models\n",
    "\n",
    "- here restricted models are, specifically: \n",
    "    - lasso(l1 norm)\n",
    "    - ridge(l2 norm)\n",
    "    - elastinet(l1 and l2 norm)\n",
    "- we have seen linear model without any restrictions; now to try out this with restrictions we have included these models\n",
    "- we will compare these models with normal linear model in two cases:\n",
    "    - first case: with default alpha\n",
    "    - second case: with best alpha in search space [to see if there is any improvement]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model names and titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[\n",
    "    {\n",
    "        'title':'Lasso Regression Model',\n",
    "        'name':Lasso,\n",
    "        'cv':LassoCV\n",
    "    },\n",
    "    {\n",
    "        'title':'Ridge Regression Model',\n",
    "        'name':Ridge,\n",
    "        'cv':RidgeCV\n",
    "    },\n",
    "    {\n",
    "        'title':'Elastinet Regression Model',\n",
    "        'name':ElasticNet,\n",
    "        'cv':ElasticNetCV\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### func used to cover restrictions linear regression models\n",
    "\n",
    "**`function params`**\n",
    "\n",
    "- cvFolds: no of folds to be used to choose best alpha in search space\n",
    "- title, modelName, modelCV: self-explanatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func used to cover with restrictions linear regression models\n",
    "def restrictModels(title,modelName,modelCV,cvFolds=10,plot=False,print=False):\n",
    "    # choosing alpha hyperparameter\n",
    "    ## create search space\n",
    "    r=np.linspace(-2,5,100)\n",
    "    alphas=np.power(10*np.ones(100),r)\n",
    "    ## get best possible alpha in search space\n",
    "    rcv=modelCV(alphas=alphas,cv=cvFolds)\n",
    "    rcv.fit(X_train_data_normalized,y_train_data)\n",
    "    cvAlpha=rcv.alpha_\n",
    "\n",
    "    # fit model\n",
    "    rlm=modelName(alpha=cvAlpha)\n",
    "    rlm.fit(X_train_data_normalized,y_train_data)\n",
    "\n",
    "    # test mse\n",
    "    preds_test=rlm.predict(X_test_data_normalized)\n",
    "    MSE_test=mean_squared_error(y_test_data,preds_test)\n",
    "\n",
    "    # train mse\n",
    "    preds_train=rlm.predict(X_train_data_normalized)\n",
    "    MSE_train=mean_squared_error(y_train_data,preds_train)\n",
    "\n",
    "    if print:\n",
    "        # some nice formatting\n",
    "        print(title)\n",
    "        print(''.center(30,'='))\n",
    "        print(f'CV alpha =',round(cvAlpha,2))\n",
    "        print(f'Train MSE =',round(MSE_train,2))\n",
    "        print(f'Test MSE =',round(MSE_test,2))\n",
    "        print(''.center(30,'='))\n",
    "\n",
    "    if plot:\n",
    "        # plot\n",
    "        coefDf = pd.DataFrame(rlm.coef_.T, columns=['Weight of Coeff'], index=X_train_data.columns)\n",
    "        coefplot(coefDf,title)\n",
    "\n",
    "    # return data dict\n",
    "    return {'Model Name':title,'Train':MSE_train,'Test':MSE_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### implementation for comparision[first case]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in models:\n",
    "    linear_models_compare.append(model(m['name'],m['title']+'(first-case)'),plot=want_to_plot,print=want_to_print)\n",
    "\n",
    "restrictedDf=pd.DataFrame(linear_models_compare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### implementation for comparision[second case]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in models:\n",
    "    linear_models_compare.append(restrictModels(m['title']+'(second-case)',m['name'],m['cv']),plot=want_to_plot,print=want_to_print)\n",
    "\n",
    "restrictedDf=pd.DataFrame(linear_models_compare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "- from below dataframe, it is clear that Lasso(second-case) does slightly better than the Normal linear model\n",
    "- Lasso (second-case) has no more overfitting problem than normal linear model does\n",
    "- also we can perform both variable selection and regularization in order to improve the prediction,accuracy and interpretability of the resulting statistical model when using Lasso((least absolute shrinkage and selection operator) Model\n",
    "- keeping these things in mind we choose **`LASSO MODEL`** out of linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal Linear Regression</td>\n",
       "      <td>56.266316</td>\n",
       "      <td>68.353944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso Regression Model(first-case)</td>\n",
       "      <td>67.983229</td>\n",
       "      <td>75.702897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge Regression Model(first-case)</td>\n",
       "      <td>56.267138</td>\n",
       "      <td>68.370663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elastinet Regression Model(first-case)</td>\n",
       "      <td>68.387424</td>\n",
       "      <td>77.608423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lasso Regression Model(second-case)</td>\n",
       "      <td>56.268430</td>\n",
       "      <td>68.322285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ridge Regression Model(second-case)</td>\n",
       "      <td>57.372207</td>\n",
       "      <td>69.851061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Elastinet Regression Model(second-case)</td>\n",
       "      <td>56.355681</td>\n",
       "      <td>68.488433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lasso Regression Model(second-case)</td>\n",
       "      <td>56.270005</td>\n",
       "      <td>68.312572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ridge Regression Model(second-case)</td>\n",
       "      <td>57.232917</td>\n",
       "      <td>69.700699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Elastinet Regression Model(second-case)</td>\n",
       "      <td>56.392747</td>\n",
       "      <td>68.530688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Model Name      Train       Test\n",
       "0                 Normal Linear Regression  56.266316  68.353944\n",
       "1       Lasso Regression Model(first-case)  67.983229  75.702897\n",
       "2       Ridge Regression Model(first-case)  56.267138  68.370663\n",
       "3   Elastinet Regression Model(first-case)  68.387424  77.608423\n",
       "4      Lasso Regression Model(second-case)  56.268430  68.322285\n",
       "5      Ridge Regression Model(second-case)  57.372207  69.851061\n",
       "6  Elastinet Regression Model(second-case)  56.355681  68.488433\n",
       "7      Lasso Regression Model(second-case)  56.270005  68.312572\n",
       "8      Ridge Regression Model(second-case)  57.232917  69.700699\n",
       "9  Elastinet Regression Model(second-case)  56.392747  68.530688"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restrictedDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=model(RandomForestRegressor,'Random Forest',plot=want_to_plot,print=want_to_print)\n",
    "model_compare.append(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Resgression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr=model(SVR,'Support Vector Resgression',plot=want_to_plot,print=want_to_print)\n",
    "model_compare.append(svr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tuning hyperparameter(C) in SVR\n",
    "\n",
    "- till now we have random forest test mse to be lowest but it is overfitting the data as its train mse is much lowwer than test mse.\n",
    "- to see if SVR outperforms random after tuning `C`(in terms of test mse), we do:\n",
    "    - work with bunch of different values of `C` and see if any one does better than Random Forest(in terms of test mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizing the parameter C in SVC\n",
    "C=[0.01,0.1,1,10,100]\n",
    "kernels=['linear', 'poly', 'rbf']\n",
    "compare_svr=[]\n",
    "for c in C:\n",
    "    for k in kernels:\n",
    "        compare_svr.append(model(SVR,f'SVR (C={c},kernel={k})',kernel=k,c=c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVR (C=0.01,kernel=linear)</td>\n",
       "      <td>78.595273</td>\n",
       "      <td>85.512479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVR (C=0.01,kernel=poly)</td>\n",
       "      <td>107.061018</td>\n",
       "      <td>106.944398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVR (C=0.01,kernel=rbf)</td>\n",
       "      <td>107.849898</td>\n",
       "      <td>106.810594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVR (C=0.1,kernel=linear)</td>\n",
       "      <td>61.927338</td>\n",
       "      <td>72.551176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVR (C=0.1,kernel=poly)</td>\n",
       "      <td>96.122849</td>\n",
       "      <td>102.794851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVR (C=0.1,kernel=rbf)</td>\n",
       "      <td>93.175259</td>\n",
       "      <td>95.846112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVR (C=1,kernel=linear)</td>\n",
       "      <td>58.242638</td>\n",
       "      <td>68.269781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVR (C=1,kernel=poly)</td>\n",
       "      <td>71.136320</td>\n",
       "      <td>119.055041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVR (C=1,kernel=rbf)</td>\n",
       "      <td>58.224402</td>\n",
       "      <td>70.018409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR (C=10,kernel=linear)</td>\n",
       "      <td>58.031517</td>\n",
       "      <td>68.133705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVR (C=10,kernel=poly)</td>\n",
       "      <td>47.509781</td>\n",
       "      <td>76.018923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVR (C=10,kernel=rbf)</td>\n",
       "      <td>30.846674</td>\n",
       "      <td>61.408842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVR (C=100,kernel=linear)</td>\n",
       "      <td>58.033115</td>\n",
       "      <td>68.103154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVR (C=100,kernel=poly)</td>\n",
       "      <td>23.740816</td>\n",
       "      <td>136.210108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVR (C=100,kernel=rbf)</td>\n",
       "      <td>7.425268</td>\n",
       "      <td>70.351542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model Name       Train        Test\n",
       "0   SVR (C=0.01,kernel=linear)   78.595273   85.512479\n",
       "1     SVR (C=0.01,kernel=poly)  107.061018  106.944398\n",
       "2      SVR (C=0.01,kernel=rbf)  107.849898  106.810594\n",
       "3    SVR (C=0.1,kernel=linear)   61.927338   72.551176\n",
       "4      SVR (C=0.1,kernel=poly)   96.122849  102.794851\n",
       "5       SVR (C=0.1,kernel=rbf)   93.175259   95.846112\n",
       "6      SVR (C=1,kernel=linear)   58.242638   68.269781\n",
       "7        SVR (C=1,kernel=poly)   71.136320  119.055041\n",
       "8         SVR (C=1,kernel=rbf)   58.224402   70.018409\n",
       "9     SVR (C=10,kernel=linear)   58.031517   68.133705\n",
       "10      SVR (C=10,kernel=poly)   47.509781   76.018923\n",
       "11       SVR (C=10,kernel=rbf)   30.846674   61.408842\n",
       "12   SVR (C=100,kernel=linear)   58.033115   68.103154\n",
       "13     SVR (C=100,kernel=poly)   23.740816  136.210108\n",
       "14      SVR (C=100,kernel=rbf)    7.425268   70.351542"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(compare_svr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### observations\n",
    "\n",
    "- only SVR with `C=10 `and `kernel='rbf'` performs better than random forest in terms of test mse\n",
    "- this also has the basic problem of overfitting the data in training as its training mse error is quite low than Lasso Linear Regression Model\n",
    "- to choose a model that is able to generalize on test data as well as does not overfit the training data, \n",
    "    #### **`we choose Lasso Linear Regression Model`** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reasons to select Lasso\n",
    "\n",
    "- Along with shrinking coefficients(Ridge also does that), lasso performs feature selection as well.\n",
    "- And since it provides sparse solutions, we can reduce our model's complexity by working with non-sparse solutions(coefficients)\n",
    "- It arbitrarily selects any one feature among the highly correlated ones and reduced the coefficients of the rest to zero. So we don't need to worry about highly correlated features. Lasso picks one for us. Although random choosing might be a problem when interpreting model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importance of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to choose feature importance\n",
    "\n",
    "- The lasso coefficients become zero in a certain range and are reduced by a constant factor, which explains there low magnitude in comparison to ridge.\n",
    "- Lasso works like a stepwise function, it reduces coef for less important features to zero and it also reduces magnitude of important features by constant factor\n",
    "![lasso image](https://www.analyticsvidhya.com/wp-content/uploads/2016/01/fig2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to minimize the cost function, Lasso regression will automatically select those features that are useful, discarding the useless or redundant features. In Lasso regression, discarding a feature will make its coefficient equal to 0.\n",
    "\n",
    "So, the idea of using Lasso regression for feature selection purposes is very simple: we fit a Lasso regression on a scaled version of our dataset and we consider only those features that have a coefficient different from 0. Obviously, we first need to tune α hyperparameter in order to have the right kind of Lasso regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lasso hyperpara-meter alpha tuning\n",
    "# search space\n",
    "r=np.linspace(-5,5,100)\n",
    "alphas=np.power(10*np.ones(100),r)\n",
    "# print(alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22051307399030456\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## get best possible alpha in search space\n",
    "rcv=LassoCV(alphas=alphas,cv=2)\n",
    "rcv.fit(X_train_data_normalized,y_train_data)\n",
    "cvAlpha=rcv.alpha_\n",
    "print(cvAlpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: IT_WholeRate ::: 0.26 :Importance\n",
      "Variable: HighSchool_WholeRate ::: 0.61 :Importance\n",
      "Variable: MedianInc_WholeAvg ::: -0.87 :Importance\n",
      "Variable: republican_rate ::: -3.46 :Importance\n",
      "Variable: Segregation ::: 2.81 :Importance\n",
      "Variable: urban ::: -0.34 :Importance\n",
      "Variable: racial_weighted_bias ::: 0.0 :Importance\n",
      "Variable: hesitancy ::: -1.79 :Importance\n",
      "Variable: HighSchool_Disparity ::: 1.31 :Importance\n",
      "Variable: IT_Disparity ::: -0.71 :Importance\n",
      "Variable: MedianInc_Disparity ::: 0.91 :Importance\n",
      "Variable: vehicle ::: 0.68 :Importance\n",
      "Variable: FacNumRate ::: -0.3 :Importance\n",
      "Variable: CaseRate ::: 2.8 :Importance\n",
      "Variable: Black_Prop ::: -2.39 :Importance\n"
     ]
    }
   ],
   "source": [
    "rf_imp=Lasso(cvAlpha)\n",
    "\n",
    "rf_imp.fit(X_train_data_normalized,y_train_data)\n",
    "\n",
    "feature_names=list(X_train_data.columns)\n",
    "\n",
    "feature_imps=list(rf_imp.coef_)\n",
    "\n",
    "l=[print(f'Variable: {name} ::: {round(imps,2)} :Importance') for name,imps in zip(feature_names,feature_imps)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### features importance in desending order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- top 8 non-sparse feature coef have been shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   name  sign importance  absolute importance\n",
      "0       republican_rate        -4.348465             4.348465\n",
      "1              CaseRate         3.196502             3.196502\n",
      "2            Black_Prop        -3.130177             3.130177\n",
      "3           Segregation         2.755837             2.755837\n",
      "4             hesitancy        -2.361170             2.361170\n",
      "5    MedianInc_WholeAvg        -2.248662             2.248662\n",
      "6  HighSchool_Disparity         1.279368             1.279368\n",
      "7               vehicle         1.247369             1.247369\n"
     ]
    }
   ],
   "source": [
    "top_imps=8\n",
    "abs_imp=[abs(imp) for imp in feature_imps]\n",
    "imp_df=pd.DataFrame({'name':feature_names,'sign importance':feature_imps,'absolute importance':abs_imp})\n",
    "imp_df.sort_values('absolute importance',kind='mergesort',ascending=False,inplace=True)\n",
    "imp_df.reset_index(drop=True,inplace=True)\n",
    "print(imp_df.head(top_imps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 8 most important features are >>>  ['republican_rate', 'CaseRate', 'Black_Prop', 'Segregation', 'hesitancy', 'MedianInc_WholeAvg', 'HighSchool_Disparity', 'vehicle']\n"
     ]
    }
   ],
   "source": [
    "print(f'Top {str(top_imps)} most important features are >>> ',list(imp_df.head(top_imps)['name']))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "365d70965140afb04a698773bfdd31483bc82432b779112c2a78b5de7c16d125"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
